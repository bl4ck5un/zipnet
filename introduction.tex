%!TEX root = main.tex

\section{Introduction}
Strong anonymous communication is a well studied problem~\cite{}. Indeed, it's a well understood trade off that you can only have either low latency or low bandwidth. [It is also increasingly important]


In an anonymous broadcast setting, users attempt to anonymously announce a message to all users. In concept, this can be modeled as a channel whose capacity C is the size of a single message. User's would then take turns. However, in practice, channels usually have large capacity relative to the message size and multiple users can broadcast at once. 

Concurrent Anonymous broadcast protocols must accomplish three tasks
\begin{enumerate}
	\item anonymously broadcast a message
	\item provide a channel access method for allowing multiple parties to use the broadcast channel
	\item provide some mechanism to prevent disruption
\end{enumerate}
All three of these steps introduce considerable overheads that to date make scaling these systems a major problem.


To date, there have been two approaches with very strong Anonymity. Heavyweight cryptographic protocols approximate shuffling mechanisms or private information retrieval.  These protocols put heavy load in servers, thus severely limiting the number of available operators.  Since one or more of the servers must be honest, this is a major impediment to deployment and widespread usage. 
Moreover, as the number of servers increase, the complexity of the protocol does not scale linearly.

To date, the design space for anonymous systems has failed to consider two key issues. 1) scalable and diverse trust assumptions . In particular, many of the most practical systems rely on heavyweight cryptographic protocols that e.g. approximate a shuffling algorithms. This induces two problems. First, these put severe load on the servers, drastically reducing the number of available parties who could run a deployed instance. The Tor Project and the EFF, for example, do not have the resources to run or admin large numbers of servers Moreover, even if a number of such parties could be found, the protocols do not practically scale to large numbers of servers. As a result, getting a diverse set of trusted parties is impossible.  This also hinders adoption.

Secondly, existing systems fail to differentiate between participant scalability and capacity scalability.  Instead, they implicitly assume that everyone who wishes to contribute to the anonymity of the system is actually also using the system to communicate. This needlessly limits the anonymity provided by the systems and poses a special problem for bootstrapping anonymous systems beyond Tor.

Take the case of privacy preserving cryptocurrencies. There are a large number of end user clients and full network nodes participating in operating the network. However, a small number of transactions are sent at any given time.
Privacy preserving cryptocurrencies need privacy at two levels: 1) on the blockchain, where the record of who paid who -- the transaction graph --- needs to be hidden  2) network layer.  Currently the best practice here is to use Tor (\imm{or I2P for monero, do we want to mention}). However, Tor offers weaker protections than the on chain layer. .... Transitioning to such a replacement, however, would immediately hit a participation gap there are less people sending private transactions in cryptocurrencies than their are using Tor at any given point in time. 

In \emph{shuffling protocols}~\cite{CCS:LYKGKM19,USENIX:AKTZ17} all encrypted messages are collected by a set of servers and then shuffled and decrypted using techniques from multi party computation. Unfortunately, shuffling protocols scale super linearly in the size of the number of messages in the round.  XXXX CHECK. 




The other approach, is that of a DC-net~\cite{JC:Chaum88}: each user submits a broadcast that obfuscates which part of the channel (if any) it writes to.  These broadcasts can then be combined to produce the final broadcast. Crucially, the combination process involves only symmetric primitives and can be done in parallel by all participants. In the original DC networks, this process was accomplished  by all parties, pairwise, sharing $|C|$ random coins.
This results in extremely low latency at the cost of two major disadvantages: 1) it is easy to disrupt 2) clients must submit $|C|$ sized messages. Even which clients have available uplink capacity, this results in servers and choke-points in the network processing $O(|C|n)$ data.



There have been two advances
\begin{itemize}
	\item The any trust model ~\cite{CCS:CorFor10}: instead of all parties communicating we pick a small number of servers who are trusted for availability and that at least one is honest. This avoids quadratic bandwidth usage and reduces each clients bandwidth requirement to simply $O(C)$: a single channel capacity length message to one of the servers. However, the network must still handle $O(Csn)$ data: i.e. bandwidth usage scales linearly in both the number of servers and the number of clients.
	\item The distributed point function approach. First introduced in~\cite{SP:CorBonMaz15}, uses cryptography to shorten the message each user submits to $O(\sqrt(C))$ at the cost of increased 
\end{itemize}


\subsection{Scheduling }
A common approach to scheduling (e.g., in Dissent~\cite{CCS:CorFor10}) is a verifiable shuffle.  We observe that  this can be replaced with a mixnet, a public shuffle phase, and an accusation phase.  In particular, the fact that clients can abort and not act on a suspicious shuffle renders the usual attacks on a mixnet moot.

In our protocol, each user submits a ephemeral epoch key via a traditional mixnet operated by each server in the any trust set. The servers operate in lock step. I.e. each server waits until it has received all submissions before striping off the outer encryption layer and forwarding, in random order, the contents to the next server. At the end, we have a clear text list of ephemeral round keys which cannot be linked to the submitters.

In and of it self, however, this is insufficient.  The last sever in the any trust set could, for example,  collude to schedule only sybils and one victim user. To prevent this, we publicly shuffle the  output using randomness contributed by each anytrust server after the mixnet finishes.


Finally, any given server could drop honest users  by colluding with dishonest ones.  This is a so called n-1 attack. However, this detectable after the fact by honest users who's messages were dropped. If the mixnet encryption is picked carefully and servers issue receipts for submitted messages, then clients can issue verifiable accusations of such and attack and refuse to participate in the next dc round. Since the any-trust setting for DCnets already requires honest servers to abort in the event of a sudden decrease in participants between rounds (also to prevent an n-1 style attack from a network adversary), this gives us safety.


Things to consider:
1) ios obfuscation instead of SGX
2) a high latency but low bandwidth mode where we only use the DCNet for checking. Note we can avoid downloading the whole mixnet output by having the output be a ciphertext under a server shared key containing both a message(itself a ciphertext) and a tag. All clients download the tags before announcing via a DCNet how to decrypt their messages.



notes:
reliability vs perfect n-1 prevention. Depends on how you deal with churn

different between participation and utilization of the channel.


Point: we need to latency numbers for uploads.





